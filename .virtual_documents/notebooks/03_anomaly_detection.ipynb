


# Cell 1: Imports and Setup
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import IsolationForest
from statsmodels.tsa.seasonal import seasonal_decompose
import warnings
warnings.filterwarnings("ignore")
plt.style.use("seaborn-v0_8-whitegrid")


# Cell 2: Load Cleaned Data
df = pd.read_csv("../data/processed/cleaned.csv")
df['Date'] = pd.to_datetime(df['Date'])
df.sort_values("Date", inplace=True)
df.head()


# Cell 3: Aggregate Sales by Date (for time-series level anomaly detection)
sales_ts = df.groupby("Date")["Weekly_Sales"].sum().reset_index()
sales_ts.set_index("Date", inplace=True)
sales_ts.head()


# Cell 4: Visualize Time Series
plt.figure(figsize=(14, 6))
plt.plot(sales_ts.index, sales_ts["Weekly_Sales"], label="Weekly Sales")
plt.title("Weekly Sales Over Time")
plt.xlabel("Date")
plt.ylabel("Sales")
plt.legend()
plt.tight_layout()
plt.show()


# Cell 5: Statistical Anomaly Detection using Z-Score
sales_ts["rolling_mean"] = sales_ts["Weekly_Sales"].rolling(window=4).mean()
sales_ts["rolling_std"] = sales_ts["Weekly_Sales"].rolling(window=4).std()
sales_ts["z_score"] = (sales_ts["Weekly_Sales"] - sales_ts["rolling_mean"]) / sales_ts["rolling_std"]

threshold = 1.39
sales_ts["anomaly_stat"] = sales_ts["z_score"].abs() > threshold

# Plot anomalies
plt.figure(figsize=(14, 6))
plt.plot(sales_ts.index, sales_ts["Weekly_Sales"], label="Weekly Sales")
plt.scatter(sales_ts[sales_ts["anomaly_stat"]].index, 
            sales_ts[sales_ts["anomaly_stat"]]["Weekly_Sales"],
            color="red", label="Anomaly", s=50)
plt.title("Statistical Anomaly Detection (Z-Score)")
plt.xlabel("Date")
plt.ylabel("Sales")
plt.legend()
plt.tight_layout()
plt.show()





# Cell 6: `
# Use aggregated weekly sales + external features
features = df.groupby("Date").agg({
    "Weekly_Sales": "sum",
    "Temperature": "mean",
    "Fuel_Price": "mean",
    "CPI": "mean",
    "Unemployment": "mean"
}).reset_index()

features["Date"] = pd.to_datetime(features["Date"])
features.set_index("Date", inplace=True)

# Model training
model = IsolationForest(contamination=0.03, random_state=42)
features["anomaly_ml"] = model.fit_predict(features)

# -1 is anomaly
features["anomaly_ml"] = features["anomaly_ml"] == -1

# Plot results
plt.figure(figsize=(14, 6))
plt.plot(features.index, features["Weekly_Sales"], label="Weekly Sales")
plt.scatter(features[features["anomaly_ml"]].index, 
            features[features["anomaly_ml"]]["Weekly_Sales"],
            color="orange", label="ML Anomaly", s=50)
plt.title("Isolation Forest – ML-based Anomaly Detection")
plt.xlabel("Date")
plt.ylabel("Sales")
plt.legend()
plt.tight_layout()
plt.show()





# Cell 7: Seasonal Decomposition (Optional Deep Dive)
result = seasonal_decompose(sales_ts["Weekly_Sales"], model='additive', period=52)
fig = result.plot()
fig.set_size_inches(14, 10)
plt.suptitle("Seasonal Decomposition of Weekly Sales", fontsize=16)
plt.tight_layout()
plt.show()


# Cell 8: Save Anomaly-Tagged Data (Optional)
output = sales_ts.copy()
output["anomaly_ml"] = features["anomaly_ml"]
output.to_csv("../data/processed/anomaly_detected.csv")
print("✅ Anomaly-tagged data saved to: ../data/processed/anomaly_detected.csv")
