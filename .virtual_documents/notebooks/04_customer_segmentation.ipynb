


# Cell 1: Imports and Setup
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings("ignore")

plt.style.use("seaborn-v0_8-whitegrid")  # or sns.set_style("whitegrid")


# Cell 2: Load Cleaned Dataset
df_cleaned = pd.read_csv("../data/processed/cleaned.csv")
df_cleaned['Date'] = pd.to_datetime(df_cleaned['Date'])

# Optional: Check data
df_cleaned.head()


# Cell 3: Aggregate Data by Store
store_data = df_cleaned.groupby('Store').agg({
    'Weekly_Sales': ['sum', 'mean'],
    'Temperature': 'mean',
    'Fuel_Price': 'mean',
    'CPI': 'mean',
    'Unemployment': 'mean',
    'Size': 'mean'
})

store_data.columns = ['_'.join(col) for col in store_data.columns]
store_data.reset_index(inplace=True)

store_data.head()


# Cell 4: Normalize Features
features = store_data.drop(columns=['Store'])
scaler = StandardScaler()
X_scaled = scaler.fit_transform(features)


# Cell 5: Elbow Method to Find Optimal Clusters
inertia = []
K = range(1, 10)

for k in K:
    km = KMeans(n_clusters=k, random_state=42)
    km.fit(X_scaled)
    inertia.append(km.inertia_)

plt.figure(figsize=(8, 4))
plt.plot(K, inertia, marker='o')
plt.title('Elbow Method For Optimal k')
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')
plt.xticks(K)
plt.grid(True)
plt.show()





# Cell 6: Fit KMeans with Optimal Clusters (e.g., 3)
optimal_k = 3
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
store_data['Cluster'] = kmeans.fit_predict(X_scaled)



# Cell 7: Visualize Clusters with PCA
pca = PCA(n_components=2)
principal_components = pca.fit_transform(X_scaled)
store_data['PC1'] = principal_components[:, 0]
store_data['PC2'] = principal_components[:, 1]

plt.figure(figsize=(8, 6))
sns.scatterplot(
    data=store_data,
    x='PC1',
    y='PC2',
    hue='Cluster',
    palette='Set2',
    s=100,
    alpha=0.8
)
plt.title('Customer Segments by Store (PCA Projection)')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.legend(title='Cluster')
plt.grid(True)
plt.show()


import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Drop any previous cluster if present
store_data = store_data.drop(columns=['Cluster'], errors='ignore')

# Define customer types using quantiles on Weekly_Sales_mean and Size_mean
conditions = [
    (store_data['Weekly_Sales_mean'] > store_data['Weekly_Sales_mean'].quantile(0.66)) & 
    (store_data['Size_mean'] > store_data['Size_mean'].quantile(0.66)),

    (store_data['Weekly_Sales_mean'] < store_data['Weekly_Sales_mean'].quantile(0.33)) & 
    (store_data['Size_mean'] < store_data['Size_mean'].quantile(0.33))
]

choices = ['High Value', 'Low Value']
store_data['Customer_Type'] = 'Medium Value'  # Default
store_data.loc[conditions[0], 'Customer_Type'] = 'High Value'
store_data.loc[conditions[1], 'Customer_Type'] = 'Low Value'

# Scatterplot without PCA
plt.figure(figsize=(10, 7))
sns.scatterplot(
    data=store_data,
    x='Weekly_Sales_mean',
    y='Size_mean',
    hue='Customer_Type',
    palette='Dark2',
    s=120,
    alpha=0.85
)
plt.title('Customer Segmentation (Statistical Rules)')
plt.xlabel('Average Weekly Sales')
plt.ylabel('Average Store Size')
plt.grid(True)
plt.legend(title='Customer Type')
plt.tight_layout()
plt.show()


# Cell 9: Export Clustered Store Data
output_path = "../data/processed/clustered_store_data.csv"
store_data.to_csv(output_path, index=False)

print(f"Clustered store data exported to: {output_path}")



