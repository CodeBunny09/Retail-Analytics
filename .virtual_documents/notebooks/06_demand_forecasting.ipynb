


import numpy as np
import pandas as pd
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import warnings
warnings.filterwarnings("ignore")


import matplotlib.pyplot as plt
%matplotlib inline


df = pd.read_csv('../data/processed/cleaned.csv', parse_dates=['Date'])


df.head()


# Group by 'Date' and sum 'Weekly_Sales'
weekly_sales = df.groupby('Date')['Weekly_Sales'].sum().reset_index()

# Resulting dataframe
print(weekly_sales)


weekly_sales.describe()


weekly_sales.info()
weekly_sales.head()
print(weekly_sales.columns)


weekly_sales.plot(x='Date', y='Weekly_Sales')
plt.show()


## Testing for stationarity

from statsmodels.tsa.stattools import adfuller


test_result = adfuller(weekly_sales['Weekly_Sales'])


def adfuller_test(sales):
    result = adfuller(sales)
    labels = ["ADF Test Statistic", "p-value", "Lags Used", "Number of Observations Used"]
    for value, label in zip(result, labels):
        print(f'{label} : {value}')
    if result[1] <= 0.5:
        print("Data has no unit and is stationary")
    else:
        print("Time series has a unit root, indicating it is non-stationary")


adfuller_test(weekly_sales['Weekly_Sales'])


weekly_sales['Seasonal First Differencec'] = weekly_sales['Weekly_Sales'] - weekly_sales['Weekly_Sales'].shift(52)
weekly_sales.tail()


adfuller_test(weekly_sales['Seasonal First Differencec'].dropna())


weekly_sales['Seasonal First Differencec'].plot()
plt.show()


from pandas.plotting import autocorrelation_plot
autocorrelation_plot(weekly_sales['Weekly_Sales'])
plt.show()


from statsmodels.graphics.tsaplots import plot_acf, plot_pacf


fig = plt.figure(figsize=(12, 9))
ax1 = fig.add_subplot(211)
fig = plot_acf(weekly_sales['Seasonal First Differencec'].iloc[54:], lags=40, ax=ax1)

ax2 = fig.add_subplot(212)
fig = plot_pacf(weekly_sales['Seasonal First Differencec'].iloc[54:], lags=40, ax=ax2)

plt.show()


from statsmodels.tsa.arima.model import ARIMA


model = ARIMA(weekly_sales['Weekly_Sales'], order=(1, 1, 1))
model_fit = model.fit()


model_fit.summary()


weekly_sales['Forecast'] = model_fit.predict(start=110, end=140, dynamic=True)
weekly_sales[['Weekly_Sales', 'Forecast']].plot(figsize=(12, 8))
plt.show()


import statsmodels.api as sm


model = sm.tsa.statespace.SARIMAX(weekly_sales['Weekly_Sales'], seasonal_order=(1,1,1,52))
results=model.fit()


weekly_sales['Forecast'] = results.predict(start=90, end=140, dynamic=True)
weekly_sales[['Weekly_Sales', 'Forecast']].plot(figsize=(12, 8))
plt.show()


import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
from statsmodels.tsa.statespace.sarimax import SARIMAX
from pandas.tseries.offsets import DateOffset
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# === Load Data ===
df = pd.read_csv('../data/processed/cleaned.csv', parse_dates=['Date'])

# === Aggregate Weekly Sales Across All Stores and Depts ===
weekly_sales = df.groupby('Date').agg({'Weekly_Sales': 'sum'}).reset_index()

# === Ensure datetime index ===
weekly_sales.index = pd.to_datetime(weekly_sales['Date'])
weekly_sales = weekly_sales.sort_index()

# === Train-Test Split ===
split_point = int(len(weekly_sales) * 0.8)
train = weekly_sales.iloc[:split_point]
test = weekly_sales.iloc[split_point:]

# === Fit SARIMA model ===
model = SARIMAX(train['Weekly_Sales'],
                order=(1, 1, 1),
                seasonal_order=(1, 1, 1, 52),
                enforce_stationarity=False,
                enforce_invertibility=False)
results = model.fit()

# === Forecast on test period ===
forecast = results.get_forecast(steps=len(test))
forecast_mean = forecast.predicted_mean

# === Evaluation ===
y_test = test['Weekly_Sales']
y_pred = forecast_mean

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
r2 = r2_score(y_test, y_pred)

# === Save metrics to file ===
os.makedirs("../output", exist_ok=True)
with open("../output/sarimax_forecast_metrics.txt", "w") as f:
    f.write(f"RMSE: {rmse:.2f}\n")
    f.write(f"MAPE: {mape:.2f}%\n")
    f.write(f"MAE: {mae:.2f}\n")
    f.write(f"RÂ² Score: {r2:.2f}\n")

# === Future Forecast ===
future_steps = 104  # 2 years ahead
future_forecast = results.predict(start=len(weekly_sales), end=len(weekly_sales)+future_steps-1, dynamic=True)

# Create future dates
future_dates = [weekly_sales.index[-1] + DateOffset(weeks=i) for i in range(1, future_steps + 1)]
fut_dataset = pd.DataFrame(index=future_dates)
fut_dataset['Weekly_Sales'] = None
fut_dataset['Forecast'] = future_forecast.values

# Combine original + forecasted future
fut_df = pd.concat([weekly_sales, fut_dataset])

# === Plot ===
fut_df[['Weekly_Sales', 'Forecast']].plot(figsize=(12, 8), title="SARIMA Weekly Sales Forecast")
plt.xlabel("Date")
plt.ylabel("Sales")
plt.grid(True)
plt.tight_layout()
plt.show()



fut_df[['Weekly_Sales', 'Forecast']].plot(figsize=(12, 8), title="SARIMA Weekly Sales Forecast")
plt.xlabel("Date")
plt.ylabel("Sales")
plt.grid(True)
plt.tight_layout()

# Save plot as PNG
plt.savefig("../output/sarimax_forecast.png")
